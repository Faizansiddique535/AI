{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7643de2-741b-45e8-96ab-cf52224cff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26619dbe-e16a-4dc1-8f47-371a037199da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a87b7f-95b6-4b67-af33-d5060e867c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Random.randint of <random.Random object at 0x136055220>>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6bc491-21a4-4b84-a9c1-d22269c16011",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbf5c67c-6fbb-455c-bc6b-2590ce8a7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cce49f6e-6881-4aa8-9a60-cff2194ff4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyAZr8mD1EP-j87_4fhFpOTiARbV2vtgKD8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81e5265-b226-4225-961c-04bce61eff54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatSession',\n",
       " 'GenerationConfig',\n",
       " 'GenerativeModel',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'annotations',\n",
       " 'caching',\n",
       " 'configure',\n",
       " 'create_tuned_model',\n",
       " 'delete_file',\n",
       " 'delete_tuned_model',\n",
       " 'embed_content',\n",
       " 'embed_content_async',\n",
       " 'get_base_model',\n",
       " 'get_file',\n",
       " 'get_model',\n",
       " 'get_operation',\n",
       " 'get_tuned_model',\n",
       " 'list_files',\n",
       " 'list_models',\n",
       " 'list_operations',\n",
       " 'list_tuned_models',\n",
       " 'protos',\n",
       " 'responder',\n",
       " 'string_utils',\n",
       " 'types',\n",
       " 'update_tuned_model',\n",
       " 'upload_file',\n",
       " 'utils']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(genai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9164952-7449-4dfd-ae59-8f4871346442",
   "metadata": {},
   "source": [
    "model_name='models/gemini-2.5-flash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cad60c6-455e-47c9-abb8-c782fcee0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='models/gemini-2.5-flash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e0c53d-c67a-45da-968a-9a71ef6730a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatSession',\n",
       " 'GenerationConfig',\n",
       " 'GenerativeModel',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'annotations',\n",
       " 'caching',\n",
       " 'configure',\n",
       " 'create_tuned_model',\n",
       " 'delete_file',\n",
       " 'delete_tuned_model',\n",
       " 'embed_content',\n",
       " 'embed_content_async',\n",
       " 'get_base_model',\n",
       " 'get_file',\n",
       " 'get_model',\n",
       " 'get_operation',\n",
       " 'get_tuned_model',\n",
       " 'list_files',\n",
       " 'list_models',\n",
       " 'list_operations',\n",
       " 'list_tuned_models',\n",
       " 'protos',\n",
       " 'responder',\n",
       " 'string_utils',\n",
       " 'types',\n",
       " 'update_tuned_model',\n",
       " 'upload_file',\n",
       " 'utils']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(genai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0490f21c-6400-45eb-88ea-53d486e2171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=genai.GenerativeModel(model_name='models/gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb66d31b-50ab-42ad-b887-fde6a58b0795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing the \"top 5\" Indian cricketers is always a challenge due to the rich history and subjective nature, but based on impact, longevity, statistics, and influence across eras, these five are almost universally recognized among the greatest:\n",
      "\n",
      "1.  **Sachin Tendulkar:** Often called the \"God of Cricket,\" Tendulkar holds almost every major batting record in both Tests and ODIs, including most runs and most centuries. His longevity (24 years) and ability to dominate bowlers across generations made him a global icon.\n",
      "\n",
      "2.  **Virat Kohli:** A modern-day batting colossus, Kohli is considered one of the greatest limited-overs batsmen of all time and has an exceptional Test record too. Known for his aggressive batting, incredible fitness, and prolific run-scoring, especially in chases, he has shattered numerous records. He also enjoyed a highly successful captaincy stint.\n",
      "\n",
      "3.  **Kapil Dev:** India's greatest fast-bowling all-rounder, Kapil Dev led India to its first Cricket World Cup victory in 1983. He was the first player to take 400 Test wickets and score 5,000 Test runs, a testament to his all-round brilliance. He truly put Indian pace bowling on the map.\n",
      "\n",
      "4.  **MS Dhoni:** One of the most successful captains in cricket history, Dhoni is the only captain to win all three major ICC limited-overs trophies (T20 World Cup, ODI World Cup, Champions Trophy). An astute leader, an exceptional finisher with the bat, and a brilliant wicketkeeper, his calm demeanor and strategic brilliance revolutionized Indian cricket.\n",
      "\n",
      "5.  **Sunil Gavaskar:** The original \"Little Master,\" Gavaskar was the first batsman to score 10,000 Test runs and 30 Test centuries. He famously dominated the fearsome West Indian fast bowlers without a helmet, setting new standards for opening batsmen with his impenetrable technique and immense concentration.\n",
      "\n",
      "This list focuses on overall impact and achievements across formats and eras. Many other legends like Rahul Dravid, Anil Kumble, Sourav Ganguly, and Rohit Sharma would be very strong contenders for a slightly expanded list.\n"
     ]
    }
   ],
   "source": [
    "response=model.generate_content(\"list of top 5 indian crickters\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798b50ae-6c22-44fa-843a-5b850abbefc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in /opt/anaconda3/lib/python3.13/site-packages (2.1.10)\n",
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain-google-genai)\n",
      "  Downloading langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting google-ai-generativelanguage<1.0.0,>=0.7.0 (from langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-google-genai) (2.10.3)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.13/site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/anaconda3/lib/python3.13/site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/anaconda3/lib/python3.13/site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.29.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.32.3)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.4.27)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.10.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.3.0)\n",
      "Downloading langchain_google_genai-3.0.0-py3-none-any.whl (57 kB)\n",
      "Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-1.0.1-py3-none-any.whl (467 kB)\n",
      "Installing collected packages: langchain-core, google-ai-generativelanguage, langchain-google-genai\n",
      "\u001b[2K  Attempting uninstall: langchain-core\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.76\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.76:\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.76\n",
      "\u001b[2K  Attempting uninstall: google-ai-generativelanguage \u001b[32m0/3\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: google-ai-generativelanguage 0.6.15hain-core]\n",
      "\u001b[2K    Uninstalling google-ai-generativelanguage-0.6.15:m0/3\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled google-ai-generativelanguage-0.6.15gchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain-google-genai━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K    Found existing installation: langchain-google-genai 2.1.10\u001b[0m \u001b[32m1/3\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K    Uninstalling langchain-google-genai-2.1.10:m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [langchain-google-genai]e]\n",
      "\u001b[2K      Successfully uninstalled langchain-google-genai-2.1.10━━\u001b[0m \u001b[32m2/3\u001b[0m [langchain-google-genai]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [langchain-google-genai]-google-genai]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "Successfully installed google-ai-generativelanguage-0.9.0 langchain-core-1.0.1 langchain-google-genai-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad9500e-9a26-4cd6-98c7-7286274894d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a56a3b-a98e-4ac6-a080-1b690102d872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AqaInput',\n",
       " 'AqaOutput',\n",
       " 'ChatGoogleGenerativeAI',\n",
       " 'DoesNotExistsException',\n",
       " 'GenAIAqa',\n",
       " 'GoogleGenerativeAI',\n",
       " 'GoogleGenerativeAIEmbeddings',\n",
       " 'GoogleVectorStore',\n",
       " 'HarmBlockThreshold',\n",
       " 'HarmCategory',\n",
       " 'Modality',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_common',\n",
       " '_compat',\n",
       " '_enums',\n",
       " '_function_utils',\n",
       " '_genai_extension',\n",
       " '_image_utils',\n",
       " 'chat_models',\n",
       " 'embeddings',\n",
       " 'genai_aqa',\n",
       " 'google_vector_store',\n",
       " 'llms']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain_google_genai\n",
    "\n",
    "dir(langchain_google_genai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d64dd4-6655-48ae-ad3e-fe0c07552763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3905c5f-82b3-4390-8187-b2c5b5de0b7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1743218380.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from langchain_google_genai\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai\n",
    "ChatGoogleGenerativeAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b33a6ff-f555-460d-83de-add27c3f71cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3747642252.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    model name\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model name\n",
    "api key \n",
    "temperature (0 , 0.7 , 1 , 1.5 , 2) (more temp more answers)\n",
    "   thinking level \n",
    "    \n",
    "\n",
    "\n",
    "top p \n",
    "cumalitive probability\n",
    "top k\n",
    "will give options and give them in the most \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6c4dd0-6d8d-4968-9f66-9ad3e7783a8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GenerativeServiceClient.generate_content() got an unexpected keyword argument 'max_retries'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[1;32m      2\u001b[0m llm\u001b[38;5;241m=\u001b[39mChatGoogleGenerativeAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemeni-2.5-flash\u001b[39m\u001b[38;5;124m\"\u001b[39m,api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIzaSyAZr8mD1EP-j87_4fhFpOTiARbV2vtgKD8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m response\u001b[38;5;241m=\u001b[39mllm\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSing a ballad of LangChain.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1999\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.code_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1997\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 1999\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:379\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    373\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AIMessage:\n\u001b[1;32m    374\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    377\u001b[0m         cast(\n\u001b[1;32m    378\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 379\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    380\u001b[0m                 [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    381\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    382\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    383\u001b[0m                 tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    384\u001b[0m                 metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    385\u001b[0m                 run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    386\u001b[0m                 run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    387\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    388\u001b[0m             )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    389\u001b[0m         )\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[1;32m    390\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1088\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1086\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m   1087\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m-> 1088\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:903\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 903\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    904\u001b[0m                 m,\n\u001b[1;32m    905\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    906\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    907\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    908\u001b[0m             )\n\u001b[1;32m    909\u001b[0m         )\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1192\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1192\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m   1193\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1194\u001b[0m     )\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:2113\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   2112\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries\n\u001b[0;32m-> 2113\u001b[0m response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[1;32m   2114\u001b[0m     request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[1;32m   2115\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2116\u001b[0m     generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[1;32m   2117\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[1;32m   2118\u001b[0m )\n\u001b[1;32m   2119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:247\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    240\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    241\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (request \u001b[38;5;241m:=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[1;32m    246\u001b[0m )\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m action(retry_state)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: rs\u001b[38;5;241m.\u001b[39moutcome\u001b[38;5;241m.\u001b[39mresult())\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:217\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mmessage:\n",
      "\u001b[0;31mTypeError\u001b[0m: GenerativeServiceClient.generate_content() got an unexpected keyword argument 'max_retries'"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm=ChatGoogleGenerativeAI(model=\"gemeni-2.5-flash\",\n",
    "                           api_key=\"AIzaSyAZr8mD1EP-j87_4fhFpOTiARbV2vtgKD8\")\n",
    "\n",
    "response=llm.invoke(\"Sing a ballad of LangChain.\")\n",
    "response.content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a04dd2-5169-4889-9cd5-b843376fb812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
